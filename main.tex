\documentclass{article}
\usepackage[letterpaper]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{xcolor}
\usepackage{natbib}
\usepackage{graphicx}
\newcommand{\red}[1]{\textcolor{red}{#1}}
\newcommand{\mat}[1]{\boldsymbol{\mathsf{#1}}}
\renewcommand{\vec}[1]{\boldsymbol{\mathrm{#1}}}
\newcommand{\R}[1]{\mathbb{R}^{#1}}

\title{Learning Nonlinear Dynamics Using Kalman Smoothing}
\author{jmsh}
\date{October 2023}

\begin{document}

\maketitle

\abstract{Identifying ODEs from measurement data requires both fitting the dynamics and assimilating the measurement data.  The Sparse Identification of Nonlinear Dynamics (SINDy) method thus involves a derivative estimation (and optionally, smoothing) step and a sparse regression on ODE terms.  Kalman smoothing provides a useful framework for assimilating the measurement data whose noise behavior is well understood.  Previously, derivatives in SINDy and its python package, pysindy, had been estimated by finite difference, L1 total variation minimization, or local filters like Savitsky-Golay.  However, Kalman discovers ODEs that best recreate the essential dynamics in simulation, and when combined with hyperparameter optimization, requires the least amount of tuning.  The authors have incorporated Kalman smoothing into the existing pysindy architecture, allowing for rapid adoption of the method.}

\section{Introduction}
The method of Sparse Identification of Nonlinear Dynamics, or SINDy, seeks to discover a differential equation governing an arbitrary, measured system.  The method takes as input some coordinate measurements over time, such as angles between molecular bonds \red{(Boninsegna article)} or a spatial field, such as wave heights \red{(Rudy article)}, and returns the best ordinary or partial differential equation (ODE or PDE) from a library.  However, the method struggles to accomodate significant measurement noise.  On the other hand, Kalman theory has a half-century history of assimilating noisy data to smooth a trajectory.  Its noise properties have been well studied. The paper integrates mature, well-established Kalman theory with emerging SINDy technology and generalized cross validation parameter selection.  It finds that the combination is competitive with other combinations of data smoothing and system identification, and has an advantage in preservation of problem structure and ease of parameter selection.

When developing model discovery methods for physical systems, explainability takes on greater importance. A method that can identify relationships between coordinates and derivatives supports all the theorems of physics, such as spectral analysis, local and global stability, and variable time-stepping.  While other time-series data science techniques have emerged such as dynamic mode decomposition, recurrent neural nets, and autoencoders, such methods do not seek to search a function space.  Applying any physical constraints to them, such as PINN \red{cite this} requires wholly new derivations.  Few tools exist to analyze the discovered models' global or local properties other than exhaustive simulation.

SINDy does seek to establish relationships between derivatives. Emerging from \red{cite original paper}, all variants aim to discover a sparse symbolic representation of an autonomous or controlled system, $\dot x = f(x)$.  This form has allowed innovations in regression that follow common physics techniques, such as bounding a Lyapunov function in \red{cite Trapping}, enforcing linear stability in \red{cite StableLinearSR3}, and weak formulation in \red{cite WeakSINDy}.  Explicitly stochastic extensions also provide symbolic representation of variance in \red{cite Boninsegna} and handle PDE discretization in \red{cite Langevin Regression}.  This paper could be considered a simpler approach in a similar vein to these latter methods.

Kalman smoothing, which this paper adds to SINDy, has a long history of assimilating measurement data in time series.  From its debut in \red{cite Kalman-original}, engineering practice and design have used it for control and prediction across the real world, e.g. in radar systems, econometric variables, weather prediction, and more.  The family of Kalman methods encompasses both smoothing, after-the-fact techniques, and filtering, real-time updates, that derive from the same assumptions for distributions.  The Kalman smoother can be considered as a best-fit Euler update, the maximum likelihood estimator of Brownian motion, or as the best linear fit of an unknown system.  In the simplest invocation, the Kalman estimator's only parameter is the ratio of measurement noise to the process's underlying stochastic noise.  Fixing both of these parameters allows Kalman methods to identify the variance of the associated estimator.  Furthermore, much work exists to attempt to identify parameters purely from data, such as \red{cite Floris, Boyd/Barrett}.  These methods include their own parameters and are not guaranteed a solution, but are an improvement on the indeterminate nature of direct maximum likelihood or MAP likelihood.

This paper introduces Kalman smoothing as the derivative estimation step in SINDy in distinction with the L1 total variation minimization or Savitsky-Golay smoothers common in application. By introducing a continuous process loss for derivative estimation, it begins to reconcile the derivative estimation step to the symbolic regression step in a principled manner.  It also allows engineering applications to incorporate SINDy estimation with a familiar data assimilation technique whose noise properties are well understood.

Section two describes the individual methods of SINDy and Kalman smoothing, providing some literature review.  In section three, experiments demonstrate the advantages of incorporating Kalman with SINDy.  The paper concludes with avenues for future research in section four.

% \begin{itemize}
%     \item Background on SINDy (relevant variants: WeakSINDy, Ensemble Kalman % *Smoothing and differentiation

\section{Background}

\subsection{SINDy}
SINDy \red{(PNAS paper)} is a family of emerging methods for discovering the underlying dynamics of a system governed by unknown or partially-known \red{(SR3 paper)} differential equations.  It can handle ODEs as well as PDEs \red{(Rudy Paper)}, and has been used for protein folding \red{(Boninsegna paper)}, chemical reaction networks \red{(Forgot paper)}, plasma physics \red{(Kaptanoglu papers)}, and more.  Most invocations occur through the pysindy Python package, but innovations such as Langevin Regression \red{(Callaham)} or \red{(Rudy integration paper)} exist as independent code.

Given some variable of interest $\mat X$ and a library of functions $\mat \Theta$ (including spatial derivatives, when relevant) SINDy seeks to find the coefficients $\mat \Xi$ of the differential equation:

\begin{align}
    \label{eqn:sindy_ode}
    \dot X = \Xi\Theta(X)
\end{align}

To amplify:
\begin{align*}
    &\mat X \in \R{n \times m}\text{: system of $n$ coordinates at $m$ timepoints.}\\
    &\mat \Theta(X) \in \R{p \times m}\text{: library of $p$ functions evaluated at $m$ timepoints}\\
    &\mat \Xi \in \R{n \times p}\text{: coefficients for $n$ equations of $p$ functions}
\end{align*}
The function library written as a time-independent quantity refers to the collection $\mat \Theta = [\theta_1, \dots \theta_p]^T$.
The method generally proceeds in two steps: 

\begin{enumerate}
    \item Estimate the time derivatives of the system ${\mat{\widehat{\dot X}}} = G(\mat X)$ for some smoothing function $G$
    \item Choosing a sparse regression method, solve the problem $\underset{\text{sparse } \mat \Xi}{\arg\min} \left\| \mat{\widehat{\dot{X}}} - \mat \Xi \mat \Theta(\mat X) \right\|^2$
\end{enumerate}
This paper seeks to make SINDy more resilient to noise by taking a data assimilation approach.  It instead presents the Kalman SINDy steps
\begin{enumerate}
    \item Estimate the state and time derivatives of the system ${\mat{\widehat{\dot X}}}, \mat{\widehat X} = G(\mat X)$ where $G$ uses Kalman smoothing
    \item Choosing a sparse regression method, solve the problem $\underset{\text{sparse } \mat \Xi}{\arg\min} \left\| \mat{\widehat{\dot{X}}} - \mat \Xi \mat \Theta(\mat {\widehat X}) \right\|^2$
\end{enumerate}

\subsection{Kalman Smoothing}

Kalman theory is a group of optimal estimation techniques to assimilate measurement noise to a random process.  The theory can be use to filter new measurements in real-time use cases or smooth a complete trajectory of measurements.  It has been used for tracking everything from aircraft trajectories to population dynamics.  While the processes this paper is concerned with are not random, 
in the first step of SINDy they are unknown, and so probabalistic language is appropriate.


In adding Kalman smoothing to SINDy, we introduce a distinction between the measurement variables and the state variables of the dynamical system in equation 
\ref{eqn:sindy_ode}.  As such, the inputs to the problem become $m$ time points of measurements of $k$ variables ($\mat Z\in \R{k\times m}$) and a linear transform from the state to the measurement variables $\mat H \in \R{k \times n}$ describing how the process is measured.  Two parameters are required $\sigma_z$, the measurement noise standard deviation, and $\sigma_x$, the process velocity standard deviation per unit time.  If only state estimates, and not variances, are required, it suffices to use the ratio $\rho = (\sigma_z / \sigma_x)^2$.

The measurement error is assumed to be normally distributed with $\mat H \mat X - \mat Z \sim \sigma_z \mathcal N(0, \mat R)$.  Each process is assumed to have an independent, Brownian velocity.  This leads to Kalman smoothing solution 
\begin{align}
    \underset{X, \dot X}{\arg\min}{\|\mat H \mat X - \mat Z\|_{R^{-1}}}^2 + \rho {\|\mat G [\mat {\dot X}, \mat X]\|_{Q^{-1}}}^2
\end{align}
Here, $\mat G$ is a linear transform to separate $[\mat{\dot X}, \mat X]$ into independent, mean-zero increments, and $\mat Q$ is the covariance of those increments.

In practice, rather than choosing $\rho$, this paper uses the generalized cross validation of (\red{Barrett and Boyd paper}) to choose $\rho$.  It chooses $\rho$ in order to minimize the loss on a witheld set of data.  While the algorithm described in that paper is not guaranteed to find a minimum, heuristic experience has shown that at least in this use case, the longer the trajectory, the more likely their algorithm will succeed.

\begin{itemize}
    \item Kalman smoother description.  Figure: graphics of kalman smoothing
    \item SINDy description.  Figure: Graphics of SINDy
    \item Anything on existing Kalman System Identification?
\end{itemize}

\section{Experiments}
\begin{figure}
    \includegraphics[height=\pdfpageheight]{images/summary-train}
\end{figure}
\begin{figure}
    \includegraphics[height=\pdfpageheight]{images/summary-test}
\end{figure}
\begin{figure}
    \includegraphics[width=\textwidth]{images/summary-metrics}
\end{figure}
Methods:
\begin{itemize}
    \item table
    \item Compare with (a) WeakSINDy, (b) TV, SG filter
    \item metrics: F1, MAE of coefficients (\textcolor{red}{or MSE?})
    \item Utilize MIOSR optimizer (\textcolor{red}{with Ensembling wrapper?})
\end{itemize}
ODE data sets \textcolor{red}{Do I add {\it all} the possible ones I have set up (Rossler, Duffing)?  Do I add the reaction network one?}
\begin{itemize}
    \item Hudson Bay Company Lotka-Volterra
    \item Van der Pol oscillator
    \item Hopf
    \item MHD \textcolor{red}{Would need to add}
\end{itemize}
PDE Data sets \textcolor{red}{anything real?}
\begin{itemize}
    \item Inviscid Burgers
    \item KdV
    \item nonlinear Schrodinger
    \item KS
    \item Reaction-Diffusion
\end{itemize}

\subsection{Noise tolerance and data length}
\textcolor{blue}{Figure: plot of score for each method across range of smoothing parameters.  subplots for each ODE \& metric}.  \textcolor{red}{Parameter-search wrapper-experiment inside P-search comparison experiment}.
% \subsection{ODEs: Robust Kalman Smoothing (Maybe?)}
\textcolor{blue}{Figure: plot of score for each method across range of smoothing parameters.  subplots for each ODE \& metric}. 
Add noisy 
\subsection{ODEs: Data Length requirements}
\textcolor{blue}{Figure: plot of score for each method at optimal parameter across range of data length requirements.  subplots for each ODE \& metric}.  \textcolor{red}{Parameter-search wrapper-experiment inside data-length wrapper-experiment inside Data-length comparison comparison experiment}.
\subsection{PDEs}
\textcolor{red}{Use Figure 4 from the E-SINDy paper. Need to implement these}
% \subsection{Model Predictive Control}
% \textcolor{red}{Lorenz stabilization, learn from E-SINDy paper}
\section{Conclusion}
This paper has demonstrated that Kalman smoothing is a 
% \begin{table}
%     \centering
%     \begin{tabular}{c|c}
%          &  \\
%          & 
%     \end{tabular}
%     \caption{Caption}
%     \label{tab:my_label}
% \end{table}
\end{document}
