@article{Raissi2019,
   abstract = {We introduce physics-informed neural networks-neural networks that are trained to solve supervised learning tasks while respecting any given laws of physics described by general nonlinear partial differential equations. In this work, we present our developments in the context of solving two main classes of problems: data-driven solution and data-driven discovery of partial differential equations. Depending on the nature and arrangement of the available data, we devise two distinct types of algorithms, namely continuous time and discrete time models. The first type of models forms a new family of data-efficient spatio-temporal function approximators, while the latter type allows the use of arbitrarily accurate implicit Runge-Kutta time stepping schemes with unlimited number of stages. The effectiveness of the proposed framework is demonstrated through a collection of classical problems in fluids, quantum mechanics, reaction-diffusion systems, and the propagation of nonlinear shallow-water waves.},
   author = {M Raissi and P Perdikaris and G E Karniadakis},
   doi = {10.1016/j.jcp.2018.10.045},
   journal = {Journal of Computational Physics},
   keywords = {Data-driven scientific computing,Kutta methods,Machine learning,Nonlinear dynamics,Predictive modeling,Runge-},
   pages = {686-707},
   title = {Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations},
   volume = {378},
   url = {www.elsevier.com/locate/jcp},
   year = {2019},
}
@article{Rudy2017,
   abstract = {We propose a sparse regression method capable of discovering the governing partial differential equation(s) of a given system by time series measurements in the spatial domain. The regression framework relies on sparsity-promoting techniques to select the nonlinear and partial derivative terms of the governing equations that most accurately represent the data, bypassing a combinatorially large search through all possible candidate models. The method balances model complexity and regression accuracy by selecting a parsimonious model via Pareto analysis. Time series measurements can be made in an Eulerian framework, where the sensors are fixed spatially , or in a Lagrangian framework, where the sensors move with the dynamics. The method is computationally efficient, robust, and demonstrated to work on a variety of canonical problems spanning a number of scientific domains including Navier-Stokes, the quantum harmonic oscillator, and the diffusion equation. Moreover, the method is capable of disambiguating between potentially nonunique dynamical terms by using multiple time series taken with different initial data. Thus, for a traveling wave, the method can distinguish between a linear wave equation and the Korteweg-de Vries equation, for instance. The method provides a promising new technique for discovering governing equations and physical laws in parameterized spatiotemporal systems, where first-principles derivations are intractable.},
   author = {Samuel H Rudy and Steven L Brunton and Joshua L Proctor and J Nathan Kutz},
   issue = {e1602614},
   journal = {Science Advances},
   title = {Data-driven discovery of partial differential equations},
   volume = {3},
   url = {https://www.science.org},
   year = {2017},
}
@article{Boninsegna2018,
   abstract = {With the rapid increase of available data for complex systems, there is great interest in the extraction of physically relevant information from massive datasets. Recently, a framework called Sparse Identification of Nonlinear Dynamics (SINDy) has been introduced to identify the governing equations of dynamical systems from simulation data. In this study, we extend SINDy to stochastic dynamical systems which are frequently used to model biophysical processes. We prove the asymptotic correctness of stochastic SINDy in the infinite data limit, both in the original and projected variables. We discuss algorithms to solve the sparse regression problem arising from the practical implementation of SINDy and show that cross validation is an essential tool to determine the right level of sparsity. We demonstrate the proposed methodology on two test systems, namely, the diffusion in a one-dimensional potential and the projected dynamics of a two-dimensional diffusion process.},
   author = {Lorenzo Boninsegna and Feliks NÃ¼ske and Cecilia Clementi},
   doi = {10.1063/1.5018409},
   issn = {00219606},
   issue = {24},
   journal = {Journal of Chemical Physics},
   month = {6},
   note = {Category: Stochastic methodsContext: Macromolecular biological systemsContribution: CV-based SSR method (is this _the_ SSR paper?). "Projected Stochastic Dynamics". Kramers-Moyal averagingClarity: Seems very clear up until it re-uses sigma.Correctness: It makes sense for now.K-M works for steady stateIt also works for projected dynamics defining nu(z)Proof: Fitting K-M regression finds the best fit to effective dynamics (App B)Free energy regressionIntroduce SSRExperiment setupGreedy search of SSR against sublibraries & CVNoise messes things up: sample move around repellersReliance on an _equilibrium_ probability distribution may not solve the problem in the general case (colored noise).},
   pmid = {29960307},
   publisher = {American Institute of Physics Inc.},
   title = {Sparse learning of stochastic dynamical equations},
   volume = {148},
   year = {2018},
}
@article{Messenger2021,
   abstract = {We present a novel weak formulation and discretization for discovering governing equations from noisy measurement data. This method of learning differential equations from data fits into a new class of algorithms that replace pointwise derivative approximations with linear transformations and variance reduction techniques. Compared to the standard SINDy algorithm presented in [S. L. Brunton, J. L. Proctor, and J. N. Kutz, Proc. Natl. Acad. Sci. USA, 113 (2016), pp. 3932-3937], our so-called weak SINDy (WSINDy) algorithm allows for reliable model identification from data with large noise (often with ratios greater than 0.1) and reduces the error in the recovered coefficients to enable accurate prediction. Moreover, the coefficient error scales linearly with the noise level, leading to high-accuracy recovery in the low-noise regime. Altogether, WSINDy combines the simplicity and efficiency of the SINDy algorithm with the natural noise reduction of integration, as demonstrated in [H. Schaeffer and S. G. McCalla, Phys. Rev. E, 96 (2017), 023302], to arrive at a robust and accurate method of sparse recovery.},
   author = {Daniel A. Messenger and David M. Bortz},
   doi = {10.1137/20M1343166},
   issn = {15403467},
   issue = {3},
   journal = {Multiscale Modeling and Simulation},
   keywords = {Adaptive grid,Data-driven model selection,Galerkin method,Generalized least squares,Nonlinear dynamics,Sparse recovery,generalized least squares,nonlinear dynamics,sparse recovery},
   pages = {1474-1497},
   publisher = {Society for Industrial and Applied Mathematics Publications},
   title = {Weak SINDy: Galerkin-based data-driven model selection},
   volume = {19},
   url = {https://doi.org/10.1137/20M1343166},
   year = {2021},
}
@article{Kaptanoglu2023,
   abstract = {Sparse system identification is the data-driven process of obtaining parsimonious differential equations that describe the evolution of a dynamical system, balancing model complexity and accuracy. There has been rapid innovation in system identification across scientific domains, but there remains a gap in the literature for large-scale methodological comparisons that are evaluated on a variety of dynamical systems. In this work, we systematically benchmark sparse regression variants by utilizing the dysts standardized database of chaotic systems introduced by Gilpin [1]. In particular, we demonstrate how this open-source tool can be used to quantitatively compare different methods of system identification. To illustrate how this benchmark can be utilized, we perform a large comparison of four algorithms for solving the sparse identification of nonlinear dynamics (SINDy) optimization problem, finding strong performance of the original algorithm and a recent mixed-integer discrete algorithm. In all cases, we used ensembling to improve the noise robustness of SINDy and provide statistical comparisons. In addition, we show very compelling evidence that the weak SINDy formulation provides significant improvements over the traditional method, even on clean data. Lastly, we investigate how Pareto-optimal models generated from SINDy algorithms depend on the properties of the equations, finding that the performance shows no significant dependence on a set of dynamical properties that quantify the amount of chaos, scale separation, degree of nonlinearity, and the syntactic complexity.},
   author = {Alan A Kaptanoglu and Lanyue Zhang and Zachary G Nicolaou and Urban Fasel and Steven L Brunton},
   keywords = {SINDy,chaos,dynamical systems,nonlinear systems,sparse regression,system identification},
   title = {Benchmarking sparse system identification with low-dimensional chaos},
}
@article{ParamOptimizationDerivatives2020,
   doi={10.1109/ACCESS.2020.3034077},
   author={F. {van Breugel} and J. {Nathan Kutz} and B. W. {Brunton}},
   journal={IEEE Access},
   title={Numerical differentiation of noisy data: A unifying multi-objective optimization framework},
   year={2020}
}
@article{Kaptanoglu2021,
   abstract = {Modeling realistic fluid and plasma flows is computationally intensive, motivating the use of reduced-order models for a variety of scientific and engineering tasks. However, it is challenging to characterize, much less guarantee, the global stability (i.e., long-time boundedness) of these models. Previous work provided a theorem outlining necessary and sufficient conditions to ensure global stability in systems with energy-preserving, quadratic nonlinearities, with the goal of evaluating the stability of projection-based models. In this work, we incorporate this theorem into modern data-driven models obtained via machine learning. First, we propose that this theorem should be a standard diagnostic for the stability of projection-based and data-driven models, examining the conditions under which it holds. Second, we illustrate how to modify the objective function in machine learning algorithms to promote globally stable models, with implications for the modeling of fluid and plasma flows. Specifically, we introduce a modified "trapping SINDy" algorithm based on the sparse identification of nonlinear dynamics (SINDy) method. This method enables the identification of models that, by construction, only produce bounded trajectories. The effectiveness and accuracy of this approach are demonstrated on a broad set of examples of varying model complexity and physical origin, including the vortex shedding in the wake of a circular cylinder.},
   author = {Alan A Kaptanoglu and Jared L Callaham and Aleksandr Aravkin and Christopher J Hansen and Steven L Brunton},
   doi = {10.1103/PhysRevFluids.6.094401},
   journal = {PHYSICAL REVIEW FLUIDS},
   keywords = {doi:10.1103/PhysRevFluids.6.094401 url:https://doi.org/10.1103/PhysRevFluids.6.094401},
   pages = {94401},
   title = {Promoting global stability in data-driven models of quadratic nonlinear dynamics},
   volume = {6},
   year = {2021},
}
@article{Hirsh2022,
   abstract = {We propose a probabilistic model discovery method for identifying ordinary differential equations governing the dynamics of observed multivariate data. Our method is based on the sparse identification of nonlinear dynamics (SINDy) framework, where models are expressed as sparse linear combinations of pre-specified candidate functions. Promoting parsimony through sparsity leads to interpretable models that generalize to unknown data. Instead of targeting point estimates of the SINDy coefficients, we estimate these coefficients via sparse Bayesian inference. The resulting method, uncertainty quantification SINDy (UQ-SINDy), quantifies not only the uncertainty in the values of the SINDy coefficients due to observation errors and limited data, but also the probability of inclusion of each candidate function in the linear combination. UQ-SINDy promotes robustness against observation noise and limited data, interpretability (in terms of model selection and inclusion probabilities) and generalization capacity for out-of-sample forecast. Sparse inference for UQSINDy employs Markov chain Monte Carlo, and we explore two sparsifying priors: the spike and slab prior, and the regularized horseshoe prior. UQ-SINDy is shown to discover accurate models in the presence of noise and with orders-ofmagnitude less data than current model discovery methods, thus providing a transformative method for real-world applications which have limited data.},
   author = {Seth M. Hirsh and David A. Barajas-Solano and J. Nathan Kutz},
   doi = {10.1098/RSOS.211823},
   issn = {20545703},
   issue = {2},
   journal = {Royal Society Open Science},
   keywords = {Bayesian inference,model discovery,uncertainty quantification},
   publisher = {Royal Society Publishing},
   title = {Sparsifying priors for Bayesian uncertainty quantification in model discovery},
   volume = {9},
   url = {https://doi.org/10.1098/rsos.211823},
   year = {2022},
}
@article{Callaham2021,
   abstract = {Many physical systems characterized by nonlinear multiscale interactions can be modelled by treating unresolved degrees of freedom as random fluctuations. However, even when the microscopic governing equations and qualitative macroscopic behaviour are known, it is often difficult to derive a stochastic model that is consistent with observations. This is especially true for systems such as turbulence where the perturbations do not behave like Gaussian white noise, introducing non-Markovian behaviour to the dynamics. We address these challenges with a framework for identifying interpretable stochastic nonlinear dynamics from experimental data, using forward and adjoint Fokker-Planck equations to enforce statistical consistency. If the form of the Langevin equation is unknown, a simple sparsifying procedure can provide an appropriate functional form. We demonstrate that this method can learn stochastic models in two artificial examples: recovering a nonlinear Langevin equation forced by coloured noise and approximating the second-order dynamics of a particle in a double-well potential with the corresponding first-order bifurcation normal form. Finally, we apply Langevin regression to experimental measurements of a turbulent bluff body wake and show that the statistical behaviour of the centre of pressure can be described by the dynamics of the corresponding laminar flow driven by nonlinear state-dependent noise.},
   author = {J. L. Callaham and J. C. Loiseau and G. Rigas and S. L. Brunton},
   doi = {10.1098/RSPA.2021.0092},
   issn = {14712946},
   issue = {2250},
   journal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
   keywords = {Fokker-Planck equation,Langevin equation,data-driven modelling,sparse regression,statistical physics Keywords: system identificatio,stochastic modelling,system identification},
   month = {6},
   note = {Category: Regression on differential equations via Fokker-Planck, rather than Langevin equation.Context: closest: [17, 18, 44, 43]-rest of references: "most successful nonlinear approach is the NARMAX framework". Also, stable linear system driven by coloured noise can reproduce second-order turbulent statistics [31]. Also cites KF [36] & info theory [37, 38]. Mentions Kramers-Moyal expansion for Monte-Carlo SINDy [17]. basics in [4].Correctness:Contributions:Clarity: What is meant by "unresolved degrees of freedom" in physics? What is meant by "all systems will have some characteristic 'Einstein-Markov' time scale over which the time evolution of macro variables may depart significantly from...[39]"? What is an "amplitude equation"25-29 for operator theory, optimal transport, and deep learning methods for modeling stoch. sys.Basically, it's SINDy, but fitting the moments, rather than the derivatives.},
   publisher = {Royal Society Publishing},
   title = {Nonlinear stochastic modelling with Langevin regression},
   volume = {477},
   year = {2021},
}
@article{Kalman1960,
   abstract = {The classical filtering and prediction problem is reexamined using the Bode-Sliannon representation of random processes and the "state-transition" method of analysis of dynamic systems. New results are: (1) The formulation and methods of solution of the problem apply without modification to stationary and nonstationary statistics and to growing-memory and infinite-memory filters. (2) A nonlinear difference (or differential) equation is derived for the covariance matrix of the optimal estimation error. From the solution of this equation the coefficients of the difference (or differential) equation of the optimal linear filter are obtained without further calculations. (3) The filtering problem is shown to be the dual of the noise-free regulator problem. The new method developed here is applied to two well-known problems, confirming and extending earlier results. The discussion is largely self-contained and proceeds from first principles; basic concepts of the theory of random processes are reviewed in the Appendix.},
   author = {R E Kalman},
   journal = {Journal of Basic Engineering},
   month = {3},
   pages = {35-45},
   title = {A New Approach to Linear Filtering and Prediction Problems 1},
   url = {http://asmedigitalcollection.asme.org/fluidsengineering/article-pdf/82/1/35/5518977/35_1.pdf},
   year = {1960},
}
@inproceedings{Barratt2020,
   abstract = {This paper considers the problem of fitting the parameters in a Kalman smoother to data. We formulate the Kalman smoothing problem with missing measurements as a constrained least squares problem and provide an efficient method to solve it based on sparse linear algebra. We then introduce the Kalman smoother tuning problem, which seeks to find parameters that achieve low prediction error on held out measurements. We derive a Kalman smoother auto-tuning algorithm, which is based on the proximal gradient method, that finds good, if not the best, parameters for a given dataset. Central to our method is the computation of the gradient of the prediction error on the held out measurements with respect to the parameters of the Kalman smoother; we describe how to compute this at little to no additional cost. We demonstrate the method on population migration within the United States as well as data collected from a smartphone's IMU+GPS system while driving.},
   author = {Shane Barratt and Stephen Boyd},
   publisher = {Proceedings of the American Control Conference},
   title = {Fitting a Kalman Smoother to Data},
   year = {2020},
}
@article{Champion2020,
   abstract = {Machine learning (ML) is redefining what is possible in data-intensive fields of science and engineering. However, applying ML to problems in the physical sciences comes with a unique set of challenges: scientists want physically interpretable models that can (i) generalize to predict previously unobserved behaviors, (ii) provide effective forecasting predictions (extrapolation), and (iii) be certifiable. Autonomous systems will necessarily interact with changing and uncertain environments, motivating the need for models that can accurately extrapolate based on physical principles (e.g. Newton's universal second law for classical mechanics, F = ma). Standard ML approaches have shown impressive performance for predicting dynamics in an interpolatory regime, but the resulting models often lack interpretability and fail to generalize. We build on a sparse regression framework that discovers governing dynamical systems models from data, selecting relevant terms in the dynamics from a library of possible functions. Our critically enabling innovation introduces a relaxed version of a sparse optimization framework that allows the use of non-convex sparsity promoting regularization functions and addresses three open challenges in scientific problems and data sets: (i) robust handling of outliers and corrupt data within noisy sensor measurements, (ii) parametric dependencies in candidate library functions, and (iii) the imposition of physical constraints. By explicitly addressing these open challenges, the integrated and unified algorithm developed provides a significant advancement over current state-of-the-art sparse model discovery methods. We show that the approach discovers parsimonious dynamical models on several example systems. This flexible approach can be tailored to the unique challenges associated with a wide range of applications and data sets, providing a powerful ML-based framework for learning governing models for physical systems from data.},
   author = {Kathleen Champion and Peng Zheng and Aleksandr Y. Aravkin and Steven L. Brunton and J. Nathan Kutz},
   doi = {10.1109/ACCESS.2020.3023625},
   issn = {21693536},
   journal = {IEEE Access},
   keywords = {Nonconvex optimization,Outlier removal,Sparse regression,Systems identification},
   pages = {169259-169271},
   title = {A unified sparse optimization framework to learn parsimonious physics-informed models from data},
   volume = {8},
   year = {2020},
}
@article{Brunton2016,
   abstract = {Extracting governing equations from data is a central challenge in many diverse areas of science and engineering. Data are abundant whereas models often remain elusive, as in climate science, neurosci-ence, ecology, finance, and epidemiology, to name only a few examples. In this work, we combine sparsity-promoting techniques and machine learning with nonlinear dynamical systems to discover governing equations from noisy measurement data. The only assumption about the structure of the model is that there are only a few important terms that govern the dynamics, so that the equations are sparse in the space of possible functions; this assumption holds for many physical systems in an appropriate basis. In particular, we use sparse regression to determine the fewest terms in the dynamic governing equations required to accurately represent the data. This results in parsimonious models that balance accuracy with model complexity to avoid overfitting. We demonstrate the algorithm on a wide range of problems, from simple canonical systems, including linear and nonlinear oscillators and the chaotic Lorenz system, to the fluid vortex shedding behind an obstacle. The fluid example illustrates the ability of this method to discover the underlying dynamics of a system that took experts in the community nearly 30 years to resolve. We also show that this method generalizes to parameterized systems and systems that are time-varying or have external forcing. dynamical systems | machine learning | sparse regression | system identification | optimization A dvances in machine learning (1) and data science (2) have promised a renaissance in the analysis and understanding of complex data, extracting patterns in vast multimodal data that are beyond the ability of humans to grasp. However, despite the rapid development of tools to understand static data based on statistical relationships, there has been slow progress in distilling physical models of dynamic processes from big data. This has limited the ability of data science models to extrapolate the dynamics beyond the attractor where they were sampled and constructed. An analogy may be drawn with the discoveries of Kepler and Newton. Kepler, equipped with the most extensive and accurate planetary data of the era, developed a data-driven model for planetary motion, resulting in his famous elliptic orbits. However, this was an attractor-based view of the world, and it did not explain the fundamental dynamic relationships that give rise to planetary orbits, or provide a model for how these bodies react when perturbed. Newton, in contrast, discovered a dynamic relationship between momentum and energy that described the underlying processes responsible for these elliptic orbits. This dynamic model may be generalized to predict behavior in regimes where no data were collected. Newton's model has proven remarkably robust for engineering design, making it possible to land a spacecraft on the moon, which would not have been possible using Kepler's model alone. A seminal breakthrough by Bongard and Lipson (3) and Schmidt and Lipson (4) has resulted in a new approach to determine the underlying structure of a nonlinear dynamical system from data. This method uses symbolic regression [i.e., genetic programming (5)] to find nonlinear differential equations, and it balances complexity of the model, measured in the number of terms, with model accuracy. The resulting model identification realizes a long-sought goal of the physics and engineering communities to discover dynamical systems from data. However, symbolic regression is expensive, does not scale well to large systems of interest, and may be prone to overfitting unless care is taken to explicitly balance model complexity with predictive power. In ref. 4, the Pareto front is used to find parsimonious models. There are other techniques that address various aspects of the dynamical system discovery problem. These include methods to discover governing equations from time-series data (6), equation-free modeling (7), empirical dynamic modeling (8, 9), modeling emergent behavior (10), and automated inference of dynamics (11-13); ref. 12 provides an excellent review. Sparse Identification of Nonlinear Dynamics (SINDy) In this work, we reenvision the dynamical system discovery problem from the perspective of sparse regression (14-16) and compressed sensing (17-22). In particular, we leverage the fact that most physical systems have only a few relevant terms that define the dynamics, making the governing equations sparse in a high-dimensional nonlinear function space. The combination of sparsity methods in dynamical systems is quite recent (23-30). Here, we consider dynamical systems (31) of the form d dt xÃ°tÃ = fÃ°xÃ°tÃÃ. [1] The vector xÃ°tÃ â R n denotes the state of a system at time t, and the function fÃ°xÃ°tÃÃ represents the dynamic constraints that define the equations of motion of the system, such as Newton's second law. Later, the dynamics will be generalized to include parameterization, time dependence, and forcing. Significance Understanding dynamic constraints and balances in nature has facilitated rapid development of knowledge and enabled technology, including aircraft, combustion engines, satellites, and electrical power. This work develops a novel framework to discover governing equations underlying a dynamical system simply from data measurements, leveraging advances in spar-sity techniques and machine learning. The resulting models are parsimonious, balancing model complexity with descriptive ability while avoiding overfitting. There are many critical data-driven problems, such as understanding cognition from neural recordings, inferring climate patterns, determining stability of financial markets, predicting and suppressing the spread of disease, and controlling turbulence for greener transportation and energy. With abundant data and elusive laws, data-driven discovery of dynamics will continue to play an important role in these efforts.},
   author = {Steven L Brunton and Joshua L Proctor and J Nathan Kutz},
   doi = {10.1073/pnas.1517384113},
   issue = {15},
   journal = {Proceedings of the National Academy of Sciences},
   note = {CategoryContext32 - Total variational derivativeContributionClarityCorrectnessAlternative to LASSO: Sequential threholded LS in Code 1 of SI Appendix1. "This guarantees that the sparse solution is found with high probability using convex methods that" - what about the drawbacks of the one-norm?2. How are derivatives measured3. Does the sparseness of the function basis affect L-1 recovery4. Choosing variable basis SI s4.5 (also using time-delay coordinates)5. SI Appendix B: when measurement and function bases are poorly chosen},
   title = {Discovering governing equations from data by sparse identification of nonlinear dynamical systems},
   volume = {113},
   year = {2016},
}
@article{Hoffmann2019,
   abstract = {The inner workings of a biological cell or a chemical reactor can be rationalized by the network of reactions, whose structure reveals the most important functional mechanisms. For complex systems, these reaction networks are not known a priori and cannot be efficiently computed with ab initio methods; therefore, an important goal is to estimate effective reaction networks from observations, such as time series of the main species. Reaction networks estimated with standard machine learning techniques such as least-squares regression may fit the observations but will typically contain spurious reactions. Here we extend the sparse identification of nonlinear dynamics (SINDy) method to vector-valued ansatz functions, each describing a particular reaction process. The resulting sparse tensor regression method "reactive SINDy" is able to estimate a parsimonious reaction network. We illustrate that a gene regulation network can be correctly estimated from observed time series.},
   author = {Moritz Hoffmann and Christoph FrÃ¶hner and Frank NoÃ©},
   doi = {10.1063/1.5066099},
   issn = {00219606},
   issue = {2},
   journal = {Journal of Chemical Physics},
   month = {1},
   pmid = {30646700},
   publisher = {American Institute of Physics Inc.},
   title = {Reactive SINDy: Discovering governing reactions from concentration data},
   volume = {150},
   year = {2019},
}
@article{Rudy2019,
   abstract = {a r t i c l e i n f o a b s t r a c t The analysis of high-dimensional dynamical systems generally requires the integration of simulation data with experimental measurements. Experimental data often has substantial amounts of measurement noise that compromises the ability to produce accurate dimen-sionality reduction, parameter estimation, reduced order models, and/or balanced models for control. Data assimilation attempts to overcome the deleterious effects of noise by producing a set of algorithms for state estimation from noisy and possibly incomplete measurements. Indeed, methods such as Kalman filtering and smoothing are vital tools for scientists in fields ranging from electronics to weather forecasting. In this work we develop a novel framework for smoothing data based on known or partially known nonlinear governing equations. The method yields superior results to current techniques when applied to problems with known deterministic dynamics. By exploiting the numerical time-stepping constraints of the deterministic system, an optimization formulation can readily extract the noise from the nonlinear dynamics in a principled manner. The superior performance is due in part to the fact that it optimizes global state estimates. We demonstrate the efficiency and efficacy of the method on a number of canonical examples, thus demonstrating its viability for the wide range of potential applications stated above.},
   author = {Samuel H Rudy and Steven L Brunton and J Nathan Kutz},
   doi = {10.1016/j.jcp.2019.108860},
   isbn = {2019.108860},
   journal = {Journal of Computational Physics},
   keywords = {Data assimilation,Denoising,Dynamical systems,Parameter estimation},
   pages = {108860},
   title = {Smoothing and parameter estimation by soft-adherence to governing equations},
   volume = {398},
   url = {www.elsevier.com/locate/jcp},
   year = {2019},
}
@article{Guan2021,
   abstract = {Convection is a fundamental fluid transport phenomenon, where the large-scale motion of a fluid is driven, for example, by a thermal gradient or an electric potential. Modelling convection has given rise to the development of chaos theory and the reduced-order modelling of multiphysics systems; however, these models have been limited to relatively simple thermal convection phenomena. In this work, we develop a reduced-order model for chaotic electroconvection at high electric Rayleigh number. The chaos in this system is related to the standard Lorenz model obtained from Rayleigh-Benard convection, although our system is driven by a more complex three-way coupling between the fluid, the charge density, and the electric field. Coherent structures are extracted from temporally and spatially resolved charge density fields via proper orthogonal decomposition (POD). A nonlinear model is then developed for the chaotic time evolution of these coherent structures using the sparse identification of nonlinear dynamics (SINDy) algorithm, constrained to preserve the symmetries observed in the original system. The resulting model exhibits the dominant chaotic dynamics of the original high-dimensional system, capturing the essential nonlinear interactions with a simple reduced-order model.},
   author = {Yifei Guan and Steven L. Brunton and Igor Novosselov},
   doi = {10.1098/rsos.202367},
   issn = {20545703},
   issue = {8},
   journal = {Royal Society Open Science},
   keywords = {Data-driven modelling,Electrohydrodynamics,Proper orthogonal decomposition,Reduced-order modelling,Sparse identification of nonlinear dynamics},
   month = {8},
   publisher = {Royal Society Publishing},
   title = {Sparse nonlinear models of chaotic electroconvection},
   volume = {8},
   year = {2021},
}
@article{Bertsimas2022,
   abstract = {Discovering governing equations of complex dynamical systems directly from data is a central problem in scientific machine learning. In recent years, the sparse identification of nonlinear dynamics (SINDy) framework, powered by heuristic sparse regression methods, has become a dominant tool for learning parsimonious models. We propose an exact formulation of the SINDy problem using mixed-integer optimization (MIO) to solve the sparsity constrained regression problem to provable optimality in seconds. On a large number of canonical ordinary and partial differential equations, we illustrate the dramatic improvement of our approach in accurate model discovery while being more sample efficient, robust to noise, and flexible in accommodating physical constraints.},
   author = {Dimitris Bertsimas and Wes Gurnee},
   title = {Learning Sparse Nonlinear Dynamics via Mixed-Integer Optimization},
   url = {http://arxiv.org/abs/2206.00176},
   year = {2022},
}
@article{Fasel2022,
   abstract = {Sparse model identification enables the discovery of nonlinear dynamical systems purely from data; however, this approach is sensitive to noise, especially in the low-data limit. In this work, we leverage the statistical approach of bootstrap aggregating (bagging) to robustify the sparse identification of the nonlinear dynamics (SINDy) algorithm. First, an ensemble of SINDy models is identified from subsets of limited and noisy data. The aggregate model statistics are then used to produce inclusion probabilities of the candidate functions, which enables uncertainty quantification and probabilistic forecasts. We apply this ensemble-SINDy (E-SINDy) algorithm to several synthetic and real-world datasets and demonstrate substantial improvements to the accuracy and robustness of model discovery from extremely noisy and limited data. For example, E-SINDy uncovers partial differential equations models from data with more than twice as much measurement noise as has been previously reported. Similarly, E-SINDy learns the Lotka Volterra dynamics from remarkably limited data of yearly lynx and hare pelts collected from 1900 to 1920. E-SINDy is computationally efficient, with similar scaling as standard SINDy. Finally, we show that ensemble statistics from E-SINDy can be exploited for active learning and improved model predictive control.},
   author = {U. Fasel and J. N. Kutz and B. W. Brunton and S. L. Brunton},
   doi = {10.1098/RSPA.2021.0904},
   issn = {14712946},
   issue = {2260},
   journal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
   keywords = {active learning,ensemble methods,model discovery,nonlinear dynamics,probabilistic forecasting,sparse regression},
   publisher = {Royal Society Publishing},
   title = {Ensemble-SINDy: Robust sparse model discovery in the low-data, high-noise limit, with active learning and control},
   volume = {478},
   year = {2022},
}
@article{Gilpin2023,
   abstract = {The striking fractal geometry of strange attractors underscores the generative nature of chaos: like probability distributions, chaotic systems can be repeatedly measured to produce arbitrarily-detailed information about the underlying attractor. Chaotic systems thus pose a unique challenge to modern statistical learning techniques, while retaining quantifiable mathematical properties that make them controllable and interpretable as benchmarks. Here, we present a growing database currently comprising 131 known chaotic dynamical systems spanning fields such as astrophysics , climatology, and biochemistry. Each system is paired with precomputed multivariate and univariate time series. Our dataset has comparable scale to existing static time series databases; however, our systems can be re-integrated to produce additional datasets of arbitrary length and granularity. Our dataset is annotated with known mathematical properties of each system, and we perform feature analysis to broadly categorize the diverse dynamics present across the collection. Chaotic systems inherently challenge forecasting models, and across extensive benchmarks we correlate forecasting performance with the degree of chaos present. We also exploit the unique generative properties of our dataset in several proof-of-concept experiments: surrogate transfer learning to improve time series classification, importance sampling to accelerate model training, and benchmarking symbolic regression algorithms.},
   author = {William Gilpin},
   title = {Chaos as an interpretable benchmark for forecasting and data-driven modelling},
   url = {https://github.com/williamgilpin/dysts},
}
